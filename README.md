# Linglitter

Tools for building a bibliographic database of linguistics journal articles,
intended to support systematic literature reviews.

## The name

Linglitter takes the linguistics litter-ature (default: from 2005 through 2025) and turns it into compact nuggets of knowledge to inspire truly useful research ... or the destruction of linguistics as we know it.

## Contents

| File | Description |
|---|---|
| `scrape_dois.py` | Fetches DOIs and metadata from the CrossRef API for journals listed in `journals.json` |
| `scrape_pdfs.py` | Downloads open-access PDFs using the Unpaywall API |
| `lookup_issns.py` | Interactive helper to look up ISSNs via CrossRef and add journals to `journals.json` |
| `journals.json` | Registry of target journals (name, publisher, ISSN) |
| `config.json` | Configuration for PDF scraping (year range, journals, politeness settings) |
| `linglitter.db` | SQLite database of scraped articles (generated by `scrape_dois.py`) |
| `bibliometrics/` | R scripts for data analysis and visualization |

## Requirements

### Python

- Python 3.8+
- `requests` (`pip install requests`)

### R (for bibliometrics)

- R 4.0+
- Packages: `DBI`, `RSQLite`, `dplyr`, `dbplyr`, `ggplot2`, `tidyr`, `scales`, `ggrepel`

```r
install.packages(c("DBI", "RSQLite", "dplyr", "dbplyr", "ggplot2", "tidyr", "scales", "ggrepel"))
```

## scrape_dois.py

Queries the [CrossRef REST API](https://api.crossref.org/) by journal ISSN and
publication-year range. Returns only items of type `journal-article`. Results
are stored in an SQLite database with DOI as primary key (re-runs are
idempotent).

### Usage

```bash
# All journals in journals.json, default years (2005--2025)
python scrape_dois.py

# Custom year range
python scrape_dois.py --from-year 2014 --until-year 2024

# Single publisher
python scrape_dois.py --publisher Benjamins

# Single journal
python scrape_dois.py --journal "Cognitive Linguistics"

# Use CrossRef polite pool for faster rate limits (recommended)
python scrape_dois.py --mailto you@example.com
```

### Options

| Flag | Default | Description |
|---|---|---|
| `--from-year` | `2005` | Start of year range, inclusive |
| `--until-year` | `2025` | End of year range, inclusive |
| `--journal` | all | Restrict to one journal (exact name from `journals.json`) |
| `--publisher` | all | Restrict to one publisher |
| `--db` | `linglitter.db` | Path to SQLite output |
| `--journals-file` | `journals.json` | Path to journal registry |
| `--mailto` | none | Email for CrossRef polite pool |

### Database schema

Table: `articles`

| Column | Type | Notes |
|---|---|---|
| `doi` | TEXT (PK) | e.g. `10.1515/cog-2022-0089` |
| `title` | TEXT | HTML tags stripped |
| `authors` | TEXT | `Family, Given; Family, Given; ...` |
| `journal` | TEXT | Full journal name from CrossRef |
| `year` | INTEGER | Publication year (prefers print over online date) |
| `volume` | TEXT | |
| `issue` | TEXT | |
| `pages` | TEXT | e.g. `261-296` |
| `publisher` | TEXT | From `journals.json` |
| `availability` | TEXT | `oa`, `no-oa`, or NULL (unknown) |
| `source` | TEXT | PDF URL from Unpaywall |
| `attempts` | INTEGER | Download attempt count (default 0) |
| `response` | INTEGER | HTTP status code (0 = no attempt) |
| `timestamp` | TEXT | ISO datetime of last attempt |
| `file` | TEXT | Relative path to downloaded PDF |

Indexed on `year` and `journal`.

## journals.json

To add a journal, append an entry:

```json
{
  "name": "Journal of Linguistics",
  "publisher": "Cambridge",
  "issn": ["0022-2267"]
}
```

ISSNs can be looked up at https://api.crossref.org/journals?query=JOURNAL+NAME.

## Current journal list

| Journal | Publisher |
|---|---|
| Cognitive Linguistics | De Gruyter |
| Cognitive Linguistic Studies | Benjamins |
| Constructions and Frames | Benjamins |
| Corpora | Edinburgh UP |
| Corpus Linguistics and Linguistic Theory | De Gruyter |
| International Journal of Corpus Linguistics | Benjamins |
| Language and Cognition | Cambridge |
| Morphology | Springer |
| Review of Cognitive Linguistics | Benjamins |
| The Mental Lexicon | Benjamins |
| Glossa | |
| Linguistic Inquiry | |
| Linguistic Analysis | |
| Theoretical Linguistics | |
| Natural Language and Linguistic Theory | |
| The Linguistic Review | |
| Journal of Memory and Language | |
| Mind and Language | |
| Language Sciences | |
| Language and Cognitive Processes | |
| Journal of Child Language | |
| Journal of Linguistics | |
| Linguistics Vanguard | |
| Languages | |
| Linguistics | |
| Lingua | |
| Language | |
| Written Language and Literacy | |
| Journal of Pragmatics | |
| Journal of Semantics | |
| Syntax and Semantics | |
| Language Variation and Change | |
| Register Studies | |
| Computational Linguistics | |
| Linguistics and Philosophy | |
| Natural Language Semantics | |
| Semantics and Pragmatics | |
| Syntax | |
| Proceedings of Sinn und Bedeutung | |
| Proceedings of the International Conference on Head-Driven Phrase Structure Grammar | |
| Cognition | |
| Language Learning | |
| Journal of Germanic Linguistics | |
| Zeitschrift für Sprachwissenschaft | |
| Zeitschrift für germanistische Linguistik | |
| Linguistische Berichte | |
| Germanistische Linguistik | |
| Zeitschrift für Dialektologie und Linguistik | |
| Journal of Language Modelling | Polish Academy of Sciences |
| Trends in Cognitive Sciences | Elsevier |
| Syntactic Theory and Research | Open Library of the Humanities |

## lookup_issns.py

Interactive helper that queries the CrossRef API for each journal name,
displays the top matches, and lets you pick the correct one (or enter an ISSN
manually). Confirmed entries are appended to `journals.json`.

```bash
# Standard interactive run
python lookup_issns.py

# With CrossRef polite pool
python lookup_issns.py --mailto you@example.com

# Preview without writing
python lookup_issns.py --dry-run
```

## scrape_pdfs.py

Downloads open-access PDFs using the [Unpaywall API](https://unpaywall.org/products/api).
Queries Unpaywall for each DOI in the database, downloads available PDFs, and
tracks download status.

### Usage

```bash
# Process one article (default)
python scrape_pdfs.py

# Process up to 100 articles
python scrape_pdfs.py --limit 100

# Run continuously until no candidates remain
python scrape_pdfs.py --continuous

# Preview without downloading
python scrape_pdfs.py --dry-run

# Use a different config file
python scrape_pdfs.py --config myconfig.json
```

### Options

| Flag | Default | Description |
|---|---|---|
| `--config` | `config.json` | Path to configuration file |
| `--db` | `linglitter.db` | Path to SQLite database |
| `--mailto` | none | Email for Unpaywall API (overrides config.json) |
| `--limit` | none | Maximum number of articles to process |
| `--continuous` | off | Run until no candidates remain |
| `--dry-run` | off | Show what would be done without downloading |

### How it works

1. Selects a random article from the database (respecting year range and journal list in config)
2. Skips articles already downloaded (`file IS NOT NULL`) or confirmed closed (`availability = 'no-oa'`)
3. Checks politeness intervals (global and per-publisher)
4. Queries Unpaywall API for the DOI
5. If OA: downloads PDF to `<data_dir>/<publisher>/<journal>/<year>/<doi>.pdf`
6. Updates database with availability status, source URL, attempt count, HTTP response, and file path

### Anti-scraping measures

The script uses browser-like headers, session cookies, and visits article landing
pages before downloading PDFs to work around publisher anti-scraping measures.
Downloaded files are verified using Content-Type headers and PDF magic bytes
(`%PDF-`) to detect when publishers serve HTML instead of PDF.

### Publisher compatibility

| Status | Publishers |
|---|---|
| Working | MDPI, OUP, PMC/NIH, De Gruyter, Benjamins, many others |
| HTML only | Wiley, Elsevier (some articles) — free HTML, paywalled PDF |
| Blocked | MIT Press (some subdomains) |

### Known limitations

- **HTML-only access**: Some publishers (Wiley, Elsevier) provide free HTML but
  require payment for PDF. These are correctly detected and skipped. Future
  enhancement: HTML-to-PDF conversion for text extraction/RAG use cases.
- **Aggressive anti-bot**: Some publishers may still block downloads. The script
  records failed attempts in the database for later retry or manual review.

## config.json

Configuration file for `scrape_pdfs.py`.

```json
{
  "years": [2020, 2025],
  "journals": ["Journal Name 1", "Journal Name 2"],
  "data_dir": "data",
  "unpaywall": {
    "mailto": "you@example.com",
    "politeness_interval": 1.0,
    "publisher_interval": 5.0,
    "max_attempts": 3
  }
}
```

| Field | Description |
|---|---|
| `years` | `[start, end]` year range (inclusive) |
| `journals` | List of journal names to process |
| `data_dir` | Directory for downloaded PDFs (default: `data`) |
| `unpaywall.mailto` | Email for Unpaywall API (or use `--mailto` flag) |
| `unpaywall.politeness_interval` | Seconds between any two download attempts |
| `unpaywall.publisher_interval` | Seconds between attempts from the same publisher |
| `unpaywall.max_attempts` | Give up after this many failed attempts per article |

## Bibliometrics (R scripts)

R scripts for analyzing the article database are in the `bibliometrics/` directory.

### publications_by_year.R

Generates line plots showing publications per journal over time.

```bash
cd bibliometrics
Rscript publications_by_year.R
```

Outputs:
- `publications_by_year_base.pdf` — Base R graphics line plot
- `publications_by_year_ggplot.pdf/.png` — ggplot2 line plot
- `publications_stacked_area.pdf/.png` — Stacked area chart (total + journal breakdown)
- `publications_stacked_proportional.pdf/.png` — 100% stacked area (journal share over time)
- `publications_by_year_faceted.pdf` — Faceted plot (one panel per journal)

## Next steps

- Additional journals / publishers as needed
- Additional PDF retrieval methods (e.g., institutional access, author repositories)

## Future steps

- Analyse citation structure
- Find most frequently cited monographs, make new database of these
- Download them also
- Some OA LangSci Press series to download and index in any case:
  
  - https://langsci-press.org/catalog/series/tbls
  - https://langsci-press.org/catalog/series/ogl
  - https://langsci-press.org/catalog/series/eotms
  - https://langsci-press.org/catalog/series/ogs
  - https://langsci-press.org/catalog/series/cogl
  - https://langsci-press.org/catalog/series/lv
  - https://langsci-press.org/catalog/series/cfls
  - https://langsci-press.org/catalog/series/frats
